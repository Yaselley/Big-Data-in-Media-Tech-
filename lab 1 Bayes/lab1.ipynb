{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAB 1 : Big Data In Media Technology \n",
    "#### Sentiment Classification with Naïve Bayesian Classifier\n",
    "\n",
    "This lab aims to understand naïve bayesian classification technique, get familiar with handly such a type of data, do data cleaning and data analysis, learn to employ python to do analysis.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan :\n",
    "    1. Data Exploration \n",
    "    2. Data Processing using NLTK \n",
    "    3. Bag of Words & TF-IDF models \n",
    "    4. Train and test the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Exploration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 import python useful packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "\u001b[33mDEPRECATION: Python 3.5 reached the end of its life on September 13th, 2020. Please upgrade your Python as Python 3.5 is no longer maintained. pip 21.0 will drop support for Python 3.5 in January 2021. pip 21.0 will remove support for this functionality.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /mnt/workspace/.local/lib/python3.5/site-packages (3.6.2)\n",
      "Requirement already satisfied: tqdm in /mnt/workspace/.local/lib/python3.5/site-packages (from nltk) (4.62.2)\n",
      "Requirement already satisfied: regex in /mnt/workspace/.local/lib/python3.5/site-packages (from nltk) (2021.8.28)\n",
      "Requirement already satisfied: click in /mnt/workspace/.local/lib/python3.5/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in /mnt/workspace/.local/lib/python3.5/site-packages (from nltk) (0.14.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sklearn as skl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import warnings\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12,12)\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 import data from csv to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Function _ csv_pd : @input : String = filename => CSV file name\n",
    "                        @ouput : dataFrame \n",
    "'''              \n",
    "def csv_pd(filename) :\n",
    "    out = pd.read_csv(filename,engine=\"python\",sep=\",\")\n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>overgeneralized, not helpful to anyone serious...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Great sound and service.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>love this book!!!: this book is a fast read ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>A hugely enjoyable screen version of Rona Jaff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>What an uninteresting hodge-podge. It could ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score                                               text\n",
       "0      0  overgeneralized, not helpful to anyone serious...\n",
       "1      1                           Great sound and service.\n",
       "2      1  love this book!!!: this book is a fast read ab...\n",
       "3      1  A hugely enjoyable screen version of Rona Jaff...\n",
       "4      0  What an uninteresting hodge-podge. It could ha..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = csv_pd(\"train.csv\")\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Verify that scores can be 0 or 1, Binary Classification\n",
    "train_data.score.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Processing Data using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Missing Values : \n",
    "def fillna(df) :\n",
    "    show = df.count() - df.isna().count()\n",
    "    print(\"Here's the count list of missing values {}\".format(show.to_frame()))\n",
    "    values = {\"score\": 0, \"text\": \"Negative\"}\n",
    "    df.fillna(value=values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's the count list of missing values        0\n",
      "score  0\n",
      "text   0\n"
     ]
    }
   ],
   "source": [
    "fillna(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /mnt/workspace/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /mnt/workspace/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Remove puntuations from text \n",
    "import string\n",
    "import re\n",
    "\n",
    "def remove_puncts(text) :\n",
    "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub(\"\\d+\", \"\", text)\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = re.sub(emoji_pattern, '', text)\n",
    "    return text \n",
    "\n",
    "def tokenize(text) :\n",
    "    text = text.split()\n",
    "    return text\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "def remove_stop_words(tokenize_text) :\n",
    "    tokenize_text = [w.lower() for w in tokenize_text if not w.lower() in stop_words]\n",
    "    return tokenize_text\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "\n",
    "def lemmating(tokenize_text):\n",
    "    tokenize_text = [wn.lemmatize(word) for word in tokenize_text]\n",
    "    return tokenize_text\n",
    "\n",
    "ps = nltk.PorterStemmer()\n",
    "ls = nltk.LancasterStemmer()\n",
    "\n",
    "def stemming(tokenize_text):\n",
    "    tokenize_text = [ps.stem(word) for word in tokenize_text]\n",
    "    tokenize_text = [ls.stem(word) for word in tokenize_text]\n",
    "    return tokenize_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_processing(df):\n",
    "    df[\"without puncts\"] =df[\"text\"].apply(lambda x: remove_puncts(x))\n",
    "    df[\"tokenize text\"] = df[\"without puncts\"].apply(lambda x: tokenize(x))\n",
    "    df[\"without stop words\"] = df[\"tokenize text\"].apply(lambda x: remove_stop_words(x))\n",
    "    df[\"lemmatized\"] = df[\"without stop words\"].apply(lambda x: lemmating(x))\n",
    "    df[\"stemming\"] = df[\"lemmatized\"].apply(lambda x:stemming(x))\n",
    "    df[\"processed\"] = df[\"stemming\"].apply(lambda x: ' '.join(str(e) for e in x))\n",
    "    return df\n",
    "    \n",
    "train_processed = apply_processing(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "      <th>without puncts</th>\n",
       "      <th>tokenize text</th>\n",
       "      <th>without stop words</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>stemming</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>overgeneralized, not helpful to anyone serious...</td>\n",
       "      <td>overgeneralized not helpful to anyone seriousl...</td>\n",
       "      <td>[overgeneralized, not, helpful, to, anyone, se...</td>\n",
       "      <td>[overgeneralized, helpful, anyone, seriously, ...</td>\n",
       "      <td>[overgeneralized, helpful, anyone, seriously, ...</td>\n",
       "      <td>[overg, help, anyon, sery, appl, prem, know, n...</td>\n",
       "      <td>overg help anyon sery appl prem know noth mean...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Great sound and service.</td>\n",
       "      <td>Great sound and service</td>\n",
       "      <td>[Great, sound, and, service]</td>\n",
       "      <td>[great, sound, service]</td>\n",
       "      <td>[great, sound, service]</td>\n",
       "      <td>[gre, sound, serv]</td>\n",
       "      <td>gre sound serv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>love this book!!!: this book is a fast read ab...</td>\n",
       "      <td>love this book this book is a fast read about ...</td>\n",
       "      <td>[love, this, book, this, book, is, a, fast, re...</td>\n",
       "      <td>[love, book, book, fast, read, poor, young, fa...</td>\n",
       "      <td>[love, book, book, fast, read, poor, young, fa...</td>\n",
       "      <td>[lov, book, book, fast, read, poor, young, far...</td>\n",
       "      <td>lov book book fast read poor young farm boy gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>A hugely enjoyable screen version of Rona Jaff...</td>\n",
       "      <td>A hugely enjoyable screen version of Rona Jaff...</td>\n",
       "      <td>[A, hugely, enjoyable, screen, version, of, Ro...</td>\n",
       "      <td>[hugely, enjoyable, screen, version, rona, jaf...</td>\n",
       "      <td>[hugely, enjoyable, screen, version, rona, jaf...</td>\n",
       "      <td>[hug, enjoy, screen, vert, ron, jaff, bestsel,...</td>\n",
       "      <td>hug enjoy screen vert ron jaff bestsel potboil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>What an uninteresting hodge-podge. It could ha...</td>\n",
       "      <td>What an uninteresting hodgepodge It could have...</td>\n",
       "      <td>[What, an, uninteresting, hodgepodge, It, coul...</td>\n",
       "      <td>[uninteresting, hodgepodge, could, something, ...</td>\n",
       "      <td>[uninteresting, hodgepodge, could, something, ...</td>\n",
       "      <td>[uninterest, hodgepodg, could, some, imagin, s...</td>\n",
       "      <td>uninterest hodgepodg could some imagin seem go...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score                                               text  \\\n",
       "0      0  overgeneralized, not helpful to anyone serious...   \n",
       "1      1                           Great sound and service.   \n",
       "2      1  love this book!!!: this book is a fast read ab...   \n",
       "3      1  A hugely enjoyable screen version of Rona Jaff...   \n",
       "4      0  What an uninteresting hodge-podge. It could ha...   \n",
       "\n",
       "                                      without puncts  \\\n",
       "0  overgeneralized not helpful to anyone seriousl...   \n",
       "1                            Great sound and service   \n",
       "2  love this book this book is a fast read about ...   \n",
       "3  A hugely enjoyable screen version of Rona Jaff...   \n",
       "4  What an uninteresting hodgepodge It could have...   \n",
       "\n",
       "                                       tokenize text  \\\n",
       "0  [overgeneralized, not, helpful, to, anyone, se...   \n",
       "1                       [Great, sound, and, service]   \n",
       "2  [love, this, book, this, book, is, a, fast, re...   \n",
       "3  [A, hugely, enjoyable, screen, version, of, Ro...   \n",
       "4  [What, an, uninteresting, hodgepodge, It, coul...   \n",
       "\n",
       "                                  without stop words  \\\n",
       "0  [overgeneralized, helpful, anyone, seriously, ...   \n",
       "1                            [great, sound, service]   \n",
       "2  [love, book, book, fast, read, poor, young, fa...   \n",
       "3  [hugely, enjoyable, screen, version, rona, jaf...   \n",
       "4  [uninteresting, hodgepodge, could, something, ...   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  [overgeneralized, helpful, anyone, seriously, ...   \n",
       "1                            [great, sound, service]   \n",
       "2  [love, book, book, fast, read, poor, young, fa...   \n",
       "3  [hugely, enjoyable, screen, version, rona, jaf...   \n",
       "4  [uninteresting, hodgepodge, could, something, ...   \n",
       "\n",
       "                                            stemming  \\\n",
       "0  [overg, help, anyon, sery, appl, prem, know, n...   \n",
       "1                                 [gre, sound, serv]   \n",
       "2  [lov, book, book, fast, read, poor, young, far...   \n",
       "3  [hug, enjoy, screen, vert, ron, jaff, bestsel,...   \n",
       "4  [uninterest, hodgepodg, could, some, imagin, s...   \n",
       "\n",
       "                                           processed  \n",
       "0  overg help anyon sery appl prem know noth mean...  \n",
       "1                                     gre sound serv  \n",
       "2  lov book book fast read poor young farm boy gr...  \n",
       "3  hug enjoy screen vert ron jaff bestsel potboil...  \n",
       "4  uninterest hodgepodg could some imagin seem go...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_processed.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Bag_of_Words and TF-IFD "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Bag of Words Model \n",
    "A bag-of-words is a representation of text that describes the occurrence of words within a document. It involves two things:\n",
    "    - A vocabulary of known words.\n",
    "    \n",
    "    - A measure of the presence of known words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "countV = CountVectorizer() # Bag Of Words\n",
    "train_countV = countV.fit_transform(train_processed.processed) # Fit the dictionnary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "print(countV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 TF-IDF Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidfV = TfidfVectorizer()\n",
    "train_tfidf = tfidfV.fit_transform(train_processed.processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train and Test The models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Datas Test and Evaluation\n",
    "test_data = csv_pd(\"test.csv\")\n",
    "evaluation_data = csv_pd(\"evaluation.csv\")\n",
    "\n",
    "## Process Datas Test and Evaluation \n",
    "test_processed = apply_processing(test_data)\n",
    "evaluation_processed = apply_processing(evaluation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Choose NLP Model (BoW or TF-IDF) wrt Naives Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def test_model_BoW(train_df,test_df,y,y_test) : \n",
    "    model_bow = Pipeline([('countV_bayes',countV),('bayes_classifier',MultinomialNB())])\n",
    "    model_bow.fit(train_df,y)\n",
    "    y_pred_train = model_bow.predict(train_df)\n",
    "    y_pred_test = model_bow.predict(test_df)\n",
    "    accuracy_train = np.mean(y_pred_train == y)\n",
    "    accuracy_test = np.mean(y_pred_test == y_test)\n",
    "    print(\"For training score Using BoW We reached {} as accuracy\".format(accuracy_train))\n",
    "    print(\"For testing score Using BoW We reached {} as accuracy\".format(accuracy_test))\n",
    "    print(\"#################End BoW with Naive Bayes#################\")\n",
    "    \n",
    "    return y_pred_train,y_pred_test\n",
    "    \n",
    "def test_model_TFIDF(train_df,test_df,y,y_test) : \n",
    "    model_TFIDF = Pipeline([('tfidfv_bayes',tfidfV),('bayes_classifier',MultinomialNB())])\n",
    "    model_TFIDF.fit(train_df,y)\n",
    "    y_pred_train = model_TFIDF.predict(train_df)\n",
    "    y_pred_test = model_TFIDF.predict(test_df)\n",
    "    accuracy_train = np.mean(y_pred_train == y)\n",
    "    accuracy_test = np.mean(y_pred_test == y_test)\n",
    "    print(\"For training score Using BoW We reached {} as accuracy\".format(accuracy_train))\n",
    "    print(\"For testing score Using BoW We reached {} as accuracy\".format(accuracy_test))\n",
    "    print(\"#################End TF-IDF with Naive Bayes#################\")\n",
    "    \n",
    "    return y_pred_train,y_pred_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training score Using BoW We reached 0.9186666666666666 as accuracy\n",
      "For testing score Using BoW We reached 0.816 as accuracy\n",
      "#################End BoW with Naive Bayes#################\n"
     ]
    }
   ],
   "source": [
    "bowtrain, bowtest = test_model_BoW(train_processed.processed,test_processed.processed,train_processed.score,test_processed.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training score Using BoW We reached 0.9248 as accuracy\n",
      "For testing score Using BoW We reached 0.8216 as accuracy\n",
      "#################End TF-IDF with Naive Bayes#################\n"
     ]
    }
   ],
   "source": [
    "tftrain, tftest = test_model_TFIDF(train_processed.processed,test_processed.processed,train_processed.score,test_processed.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3587,  161],\n",
       "       [ 403, 3349]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Display Confusion Matrix \n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(train_data.score, bowtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training score Using BoW We reached 0.9186666666666666 as accuracy\n",
      "For testing score Using BoW We reached 0.7952 as accuracy\n",
      "#################End BoW with Naive Bayes#################\n"
     ]
    }
   ],
   "source": [
    "tftrain, tftest = test_model_BoW(train_processed.processed,evaluation_processed.processed,train_processed.score,evaluation_processed.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
